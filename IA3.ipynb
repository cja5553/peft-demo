{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab5f4839",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef2849bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from peft import (\n",
    "    get_peft_config,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    IA3Config,\n",
    "    IA3Model,\n",
    "    PeftType)\n",
    "from evaluate import load\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, get_linear_schedule_with_warmup, set_seed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af989af",
   "metadata": {},
   "source": [
    "# Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16a427e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I wonder what would happen if I were to tell s...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when you find out the initiative isn't even a ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have a job interview with @BarclaysUK in Lou...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Fly_Norwegian quite simply the #worst #airlin...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaaaaaaaad! Should have stayed in London!</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>if you do me wrong i will not hesitate to bloc...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3609</th>\n",
       "      <td>@EducatedNPetty white pricks that were laughin...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3610</th>\n",
       "      <td>People often grudge others what they cannot en...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>@OnyxFlare25 She chuckles, shaking her head. '...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>@PottzGaming hmu need players for lans next ye...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3613 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    label  intensity\n",
       "0     I wonder what would happen if I were to tell s...    anger      0.458\n",
       "1     when you find out the initiative isn't even a ...    anger      0.312\n",
       "2     I have a job interview with @BarclaysUK in Lou...     fear      0.720\n",
       "3     @Fly_Norwegian quite simply the #worst #airlin...  sadness      0.667\n",
       "4             Gaaaaaaaad! Should have stayed in London!  sadness      0.562\n",
       "...                                                 ...      ...        ...\n",
       "3608  if you do me wrong i will not hesitate to bloc...     fear      0.250\n",
       "3609  @EducatedNPetty white pricks that were laughin...      joy      0.250\n",
       "3610  People often grudge others what they cannot en...    anger      0.396\n",
       "3611  @OnyxFlare25 She chuckles, shaking her head. '...     fear      0.271\n",
       "3612  @PottzGaming hmu need players for lans next ye...  sadness      0.125\n",
       "\n",
       "[3613 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#load train data\n",
    "\n",
    "def get_file(path):\n",
    "    cols = ['id', 'text', 'label', 'intensity']\n",
    "    anger = pd.read_csv(path + 'anger.txt', header=None, sep='\\t', names=cols, index_col=0)\n",
    "    fear = pd.read_csv(path + 'fear.txt', header=None, sep='\\t', names=cols, index_col=0)\n",
    "    sad = pd.read_csv(path + 'sadness.txt', header=None, sep='\\t', names=cols, index_col=0)\n",
    "    joy = pd.read_csv(path + 'joy.txt', header=None, sep='\\t', names=cols, index_col=0)\n",
    "    # Combine the DataFrames\n",
    "    combined_df = pd.concat([anger, fear, sad, joy])\n",
    "    # Shuffle the combined DataFrame\n",
    "    shuffled = combined_df.sample(frac=1).reset_index(drop=True)\n",
    "    return shuffled\n",
    "\n",
    "train=get_file(\"train/\")\n",
    "val=get_file(\"Dev/\")\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1985880c",
   "metadata": {},
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c22eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.dataframe.iloc[idx]['text']\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "\n",
    "        # Tokenize the sentence\n",
    "        inputs = self.tokenizer(sentence, truncation=True, max_length=None, return_tensors=\"pt\")\n",
    "        inputs = {key: val.squeeze(0) for key, val in inputs.items()}\n",
    "\n",
    "        # Convert label to a numeric format if necessary\n",
    "        label_to_id = {'joy': 0, 'anger': 1, 'fear': 2, 'sadness': 3}\n",
    "        label_id = label_to_id[label]\n",
    "\n",
    "        inputs['labels'] = torch.tensor(label_id, dtype=torch.long)\n",
    "\n",
    "        return inputs\n",
    "\n",
    "def collate_fn(examples):\n",
    "    return tokenizer.pad(examples, padding=\"longest\", return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c55488f",
   "metadata": {},
   "source": [
    "# Define the IA3 configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c92f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "model_name_or_path = \"cardiffnlp/twitter-roberta-base-emotion\"\n",
    "peft_type = PeftType.IA3\n",
    "device = \"cuda\"\n",
    "num_epochs = 4\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89280351",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = IA3Config(task_type=\"SEQ_CLS\") \n",
    "lr = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7cdbfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path,padding_side='left')\n",
    "label_to_id = {'joy': 0, 'anger': 1, 'fear': 2, 'sadness': 3}\n",
    "# Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, num_labels=len(label_to_id))\n",
    "\n",
    "train_dataset = EmotionDataset(train, tokenizer)\n",
    "val_dataset = EmotionDataset(val, tokenizer)\n",
    "# Use the collate_fn in your DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, collate_fn=collate_fn, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_dataset, shuffle=True, collate_fn=collate_fn, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdba4786",
   "metadata": {},
   "source": [
    "# Define the pre-trained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6ef081a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 658,180 || all params: 125,306,888 || trainable%: 0.5252544457093212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): IA3Model(\n",
       "    (model): PeftModelForSequenceClassification(\n",
       "      (base_model): IA3Model(\n",
       "        (model): RobertaForSequenceClassification(\n",
       "          (roberta): RobertaModel(\n",
       "            (embeddings): RobertaEmbeddings(\n",
       "              (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "              (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "              (token_type_embeddings): Embedding(1, 768)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (encoder): RobertaEncoder(\n",
       "              (layer): ModuleList(\n",
       "                (0-11): 12 x RobertaLayer(\n",
       "                  (attention): RobertaAttention(\n",
       "                    (self): RobertaSelfAttention(\n",
       "                      (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                      (key): Linear(\n",
       "                        in_features=768, out_features=768, bias=True\n",
       "                        (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 768x1])\n",
       "                      )\n",
       "                      (value): Linear(\n",
       "                        in_features=768, out_features=768, bias=True\n",
       "                        (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 768x1])\n",
       "                      )\n",
       "                      (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (output): RobertaSelfOutput(\n",
       "                      (dense): Linear(\n",
       "                        in_features=768, out_features=768, bias=True\n",
       "                        (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 1x768])\n",
       "                      )\n",
       "                      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                      (dropout): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): RobertaIntermediate(\n",
       "                    (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                    (intermediate_act_fn): GELUActivation()\n",
       "                  )\n",
       "                  (output): RobertaOutput(\n",
       "                    (dense): Linear(\n",
       "                      in_features=3072, out_features=768, bias=True\n",
       "                      (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 1x3072])\n",
       "                    )\n",
       "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                    (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (classifier): ModulesToSaveWrapper(\n",
       "            (original_module): RobertaClassificationHead(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "            )\n",
       "            (modules_to_save): ModuleDict(\n",
       "              (default): RobertaClassificationHead(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8179d2a",
   "metadata": {},
   "source": [
    "# Define the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8fe54b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(params=model.parameters(), lr=lr)\n",
    "\n",
    "# Instantiate scheduler\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0.06 * (len(train_dataloader) * num_epochs),\n",
    "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1624c0",
   "metadata": {},
   "source": [
    "# Fine-tune!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0531811f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/226 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 226/226 [00:05<00:00, 39.51it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 74.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7953890489913544\n",
      "F1 Score: 0.7913822737485547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 226/226 [00:05<00:00, 44.18it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 76.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8213256484149856\n",
      "F1 Score: 0.8211573536049607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 226/226 [00:05<00:00, 44.20it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 77.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8184438040345822\n",
      "F1 Score: 0.8193410382971343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 226/226 [00:05<00:00, 43.98it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 79.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8530259365994236\n",
      "F1 Score: 0.8529870003850506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "f1_metric = load('f1', config_name='multiclass', average='weighted')\n",
    "accuracy_metric = load('accuracy')\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    for step, batch in enumerate(tqdm(val_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        predictions, references = predictions, batch[\"labels\"]\n",
    "        accuracy_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "        f1_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "    # Compute final metric values\n",
    "    final_accuracy = accuracy_metric.compute()\n",
    "    final_f1 = f1_metric.compute(average='weighted')\n",
    "    print(f\"Accuracy: {final_accuracy['accuracy']}\")\n",
    "    print(f\"F1 Score: {final_f1['f1']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d762c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
