{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09ec5e1e",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef2849bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from peft import (\n",
    "    get_peft_config,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    set_peft_model_state_dict,\n",
    "    PeftType,\n",
    "    PrefixTuningConfig,\n",
    "    PromptEncoderConfig,\n",
    ")\n",
    "\n",
    "from evaluate import load\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, get_linear_schedule_with_warmup, set_seed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07feb976",
   "metadata": {},
   "source": [
    "# Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16a427e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#load train data\n",
    "\n",
    "def get_file(path):\n",
    "    cols = ['id', 'text', 'label', 'intensity']\n",
    "    anger = pd.read_csv(path + 'anger.txt', header=None, sep='\\t', names=cols, index_col=0)\n",
    "    fear = pd.read_csv(path + 'fear.txt', header=None, sep='\\t', names=cols, index_col=0)\n",
    "    sad = pd.read_csv(path + 'sadness.txt', header=None, sep='\\t', names=cols, index_col=0)\n",
    "    joy = pd.read_csv(path + 'joy.txt', header=None, sep='\\t', names=cols, index_col=0)\n",
    "    # Combine the DataFrames\n",
    "    combined_df = pd.concat([anger, fear, sad, joy])\n",
    "    # Shuffle the combined DataFrame\n",
    "    shuffled = combined_df.sample(frac=1).reset_index(drop=True)\n",
    "    return shuffled\n",
    "\n",
    "train=get_file(\"train/\")\n",
    "val=get_file(\"Dev/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "018741a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@lebara - worst possible decision I could have...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Has anyone noticed that @npr stories in recent...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@___margs @juliana_f_reyes Hey Michael! Thanks...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trying to loveee somebody, just wanna love som...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#picoftheday : How...why... Really... !!\\n    ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>Transitioning to a new job is hard when you ha...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3609</th>\n",
       "      <td>@ily_geuly call me now I'm laying in my bed mo...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3610</th>\n",
       "      <td>All the 'juniors' are now wearing purple at ol...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3611</th>\n",
       "      <td>Wearing all black tomorrow as I continue to mo...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>@UnknownAndYoung — a low growl escaping him. O...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3613 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text    label  intensity\n",
       "0     @lebara - worst possible decision I could have...  sadness      0.479\n",
       "1     Has anyone noticed that @npr stories in recent...  sadness      0.500\n",
       "2     @___margs @juliana_f_reyes Hey Michael! Thanks...     fear      0.250\n",
       "3     Trying to loveee somebody, just wanna love som...      joy      0.354\n",
       "4     #picoftheday : How...why... Really... !!\\n    ...     fear      0.362\n",
       "...                                                 ...      ...        ...\n",
       "3608  Transitioning to a new job is hard when you ha...      joy      0.521\n",
       "3609  @ily_geuly call me now I'm laying in my bed mo...  sadness      0.740\n",
       "3610  All the 'juniors' are now wearing purple at ol...  sadness      0.646\n",
       "3611  Wearing all black tomorrow as I continue to mo...  sadness      0.779\n",
       "3612  @UnknownAndYoung — a low growl escaping him. O...    anger      0.396\n",
       "\n",
       "[3613 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df30e64",
   "metadata": {},
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c22eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.dataframe.iloc[idx]['text']\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "\n",
    "        # Tokenize the sentence\n",
    "        inputs = self.tokenizer(sentence, truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n",
    "        inputs = {key: val.squeeze(0) for key, val in inputs.items()}\n",
    "\n",
    "        # Convert label to a numeric format if necessary\n",
    "        label_to_id = {'joy': 0, 'anger': 1, 'fear': 2, 'sadness': 3}\n",
    "        label_id = label_to_id[label]\n",
    "\n",
    "        inputs['labels'] = torch.tensor(label_id, dtype=torch.long)\n",
    "\n",
    "        return inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff93850",
   "metadata": {},
   "source": [
    "# Define the prefix tuning configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c92f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "model_name_or_path = \"cardiffnlp/twitter-roberta-base-emotion\"\n",
    "peft_type = PeftType.PREFIX_TUNING\n",
    "device = \"cuda\"\n",
    "num_epochs = 4\n",
    "\n",
    "peft_config = PrefixTuningConfig(task_type=\"SEQ_CLS\", num_virtual_tokens=10)\n",
    "lr = 0.008\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3896b535",
   "metadata": {},
   "source": [
    "# Define the pre-trained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7cdbfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path,padding_side='left')\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = EmotionDataset(train, tokenizer)\n",
    "val_dataset = EmotionDataset(val, tokenizer)\n",
    "\n",
    "# DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_dataset, shuffle=False, batch_size=batch_size)\n",
    "label_to_id = {'joy': 0, 'anger': 1, 'fear': 2, 'sadness': 3}\n",
    "# Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, num_labels=len(label_to_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79880b14",
   "metadata": {},
   "source": [
    "## Print the model and peft details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6ef081a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 777,988 || all params: 125,426,696 || trainable%: 0.6202730557456444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): RobertaForSequenceClassification(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): ModulesToSaveWrapper(\n",
       "      (original_module): RobertaClassificationHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "      )\n",
       "      (modules_to_save): ModuleDict(\n",
       "        (default): RobertaClassificationHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (prompt_encoder): ModuleDict(\n",
       "    (default): PrefixEncoder(\n",
       "      (embedding): Embedding(10, 18432)\n",
       "    )\n",
       "  )\n",
       "  (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d872c21c",
   "metadata": {},
   "source": [
    "# Define the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8fe54b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(params=model.parameters(), lr=lr)\n",
    "\n",
    "# Instantiate scheduler\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0.06 * (len(train_dataloader) * num_epochs),\n",
    "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373222db",
   "metadata": {},
   "source": [
    "# Fine-tune!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0531811f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 226/226 [00:45<00:00,  4.98it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:02<00:00,  9.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6570605187319885\n",
      "F1 Score: 0.6567599975141224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 226/226 [00:44<00:00,  5.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:02<00:00,  9.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7319884726224783\n",
      "F1 Score: 0.729596788945238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 226/226 [00:44<00:00,  5.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:02<00:00,  9.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6829971181556196\n",
      "F1 Score: 0.6758584106853177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 226/226 [00:45<00:00,  5.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:02<00:00,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7809798270893372\n",
      "F1 Score: 0.779587184263078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "f1_metric = load('f1', config_name='multiclass', average='weighted')\n",
    "accuracy_metric = load('accuracy')\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    for step, batch in enumerate(tqdm(val_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        predictions, references = predictions, batch[\"labels\"]\n",
    "        accuracy_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "        f1_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "    # Compute final metric values\n",
    "    final_accuracy = accuracy_metric.compute()\n",
    "    final_f1 = f1_metric.compute(average='weighted')\n",
    "    print(f\"Accuracy: {final_accuracy['accuracy']}\")\n",
    "    print(f\"F1 Score: {final_f1['f1']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f99d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
